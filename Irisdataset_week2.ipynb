{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afca5e63-0880-4ce7-9753-2008c1a2b2a7",
   "metadata": {},
   "source": [
    "# Week 2 Statistical Foundations in Data Processing\n",
    "\n",
    "## Descriptive Statistics\n",
    "\n",
    "#### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce3d1740-6334-4f9d-a230-0f96fb5c7df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Sepal Length: 5.84\n",
      "Mean Sepal Width: 3.05\n",
      "Mean Petal Length: 3.76\n",
      "Mean Petal Width: 1.20\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Iris dataset\n",
    "\n",
    "url = 'iris.csv'  # Change this to the path of your downloaded file\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "iris_data = pd.read_csv(url, header=None, names=column_names)\n",
    "df = pd.DataFrame(data=iris_data, columns=column_names)\n",
    "\n",
    "# Calculate the mean for each feature\n",
    "mean_sepal_length = np.mean(iris_data['sepal_length'])\n",
    "mean_sepal_width = np.mean(iris_data['sepal_width'])\n",
    "mean_petal_length = np.mean(iris_data['petal_length'])\n",
    "mean_petal_width = np.mean(iris_data['petal_width'])\n",
    "\n",
    "print(f\"Mean Sepal Length: {mean_sepal_length:.2f}\")\n",
    "print(f\"Mean Sepal Width: {mean_sepal_width:.2f}\")\n",
    "print(f\"Mean Petal Length: {mean_petal_length:.2f}\")\n",
    "print(f\"Mean Petal Width: {mean_petal_width:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bd378b3-2df4-4031-ac5d-8fbc4db26b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Sepal Length: 5.80\n",
      "Median Sepal Width: 3.00\n",
      "Median Petal Length: 4.35\n",
      "Median Petal Width: 1.30\n"
     ]
    }
   ],
   "source": [
    "# Calculate the median for each feature\n",
    "median_sepal_length = np.median(iris_data['sepal_length'])\n",
    "median_sepal_width = np.median(iris_data['sepal_width'])\n",
    "median_petal_length = np.median(iris_data['petal_length'])\n",
    "median_petal_width = np.median(iris_data['petal_width'])\n",
    "\n",
    "print(f\"Median Sepal Length: {median_sepal_length:.2f}\")\n",
    "print(f\"Median Sepal Width: {median_sepal_width:.2f}\")\n",
    "print(f\"Median Petal Length: {median_petal_length:.2f}\")\n",
    "print(f\"Median Petal Width: {median_petal_width:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a790bae-53bc-4464-b00d-58feca4abc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode Sepal Length: [5.]\n",
      "Mode Sepal Width: [3.]\n",
      "Mode Petal Length: [1.5]\n",
      "Mode Petal Width: [0.2]\n"
     ]
    }
   ],
   "source": [
    "# Determine the mode for each feature\n",
    "mode_sepal_length = iris_data['sepal_length'].mode()\n",
    "mode_sepal_width = iris_data['sepal_width'].mode()\n",
    "mode_petal_length = iris_data['petal_length'].mode()\n",
    "mode_petal_width = iris_data['petal_width'].mode()\n",
    "\n",
    "print(f\"Mode Sepal Length: {mode_sepal_length.values}\")\n",
    "print(f\"Mode Sepal Width: {mode_sepal_width.values}\")\n",
    "print(f\"Mode Petal Length: {mode_petal_length.values}\")\n",
    "print(f\"Mode Petal Width: {mode_petal_width.values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8bf7416-df04-4114-842b-9fad71e5e3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range Sepal Length: 3.60\n",
      "Range Sepal Width: 2.40\n",
      "Range Petal Length: 5.90\n",
      "Range Petal Width: 2.40\n"
     ]
    }
   ],
   "source": [
    "# Calculate the range for each feature\n",
    "range_sepal_length = np.max(iris_data['sepal_length']) - np.min(iris_data['sepal_length'])\n",
    "range_sepal_width = np.max(iris_data['sepal_width']) - np.min(iris_data['sepal_width'])\n",
    "range_petal_length = np.max(iris_data['petal_length']) - np.min(iris_data['petal_length'])\n",
    "range_petal_width = np.max(iris_data['petal_width']) - np.min(iris_data['petal_width'])\n",
    "\n",
    "print(f\"Range Sepal Length: {range_sepal_length:.2f}\")\n",
    "print(f\"Range Sepal Width: {range_sepal_width:.2f}\")\n",
    "print(f\"Range Petal Length: {range_petal_length:.2f}\")\n",
    "print(f\"Range Petal Width: {range_petal_width:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b4e722-1501-4e46-933c-179e4db24e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance Sepal Length: 0.68\n",
      "Variance Sepal Width: 0.19\n",
      "Variance Petal Length: 3.09\n",
      "Variance Petal Width: 0.58\n"
     ]
    }
   ],
   "source": [
    "# Calculate the variance for each feature\n",
    "variance_sepal_length = np.var(iris_data['sepal_length'])\n",
    "variance_sepal_width = np.var(iris_data['sepal_width'])\n",
    "variance_petal_length = np.var(iris_data['petal_length'])\n",
    "variance_petal_width = np.var(iris_data['petal_width'])\n",
    "\n",
    "print(f\"Variance Sepal Length: {variance_sepal_length:.2f}\")\n",
    "print(f\"Variance Sepal Width: {variance_sepal_width:.2f}\")\n",
    "print(f\"Variance Petal Length: {variance_petal_length:.2f}\")\n",
    "print(f\"Variance Petal Width: {variance_petal_width:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7edbab74-de20-49dd-8f5a-cda07d8c8a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation Sepal Length: 0.83\n",
      "Standard Deviation Sepal Width: 0.43\n",
      "Standard Deviation Petal Length: 1.76\n",
      "Standard Deviation Petal Width: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Calculate the standard deviation for each feature\n",
    "std_sepal_length = np.std(iris_data['sepal_length'])\n",
    "std_sepal_width = np.std(iris_data['sepal_width'])\n",
    "std_petal_length = np.std(iris_data['petal_length'])\n",
    "std_petal_width = np.std(iris_data['petal_width'])\n",
    "\n",
    "print(f\"Standard Deviation Sepal Length: {std_sepal_length:.2f}\")\n",
    "print(f\"Standard Deviation Sepal Width: {std_sepal_width:.2f}\")\n",
    "print(f\"Standard Deviation Petal Length: {std_petal_length:.2f}\")\n",
    "print(f\"Standard Deviation Petal Width: {std_petal_width:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a4e343-51f1-46c9-9ce8-1db608e6d2aa",
   "metadata": {},
   "source": [
    "### Day 2 Data Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54c19a5d-6fee-4977-8f4b-81e8b961c75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153 entries, 0 to 152\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  153 non-null    float64\n",
      " 1   sepal_width   153 non-null    float64\n",
      " 2   petal_length  153 non-null    object \n",
      " 3   petal_width   152 non-null    float64\n",
      " 4   class         150 non-null    object \n",
      "dtypes: float64(3), object(2)\n",
      "memory usage: 6.1+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Correctly load the dataset\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "iris_data = pd.read_csv('iris_preprocess.csv', names=column_names)\n",
    "\n",
    "iris_data.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c31f8bf-35ac-4f20-9238-e70f12af58aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    object \n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   class         150 non-null    object \n",
      "dtypes: float64(3), object(2)\n",
      "memory usage: 7.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Remove instances with missing values\n",
    "iris_data_cleaned = iris_data.dropna()\n",
    "\n",
    "iris_data_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e3cc34e-99d9-43a0-b6bf-1a2a540cd344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width    petal_length  petal_width           class\n",
      "0             5.1          3.5             1.4     0.200000     Iris-setosa\n",
      "1             4.9          3.0             1.4     0.200000     Iris-setosa\n",
      "2             4.7          3.2             1.3     0.200000     Iris-setosa\n",
      "3             4.6          3.1             1.5     0.200000     Iris-setosa\n",
      "4             5.0          3.6             1.4     0.200000     Iris-setosa\n",
      "..            ...          ...             ...          ...             ...\n",
      "148           6.2          3.4             5.4     2.300000  Iris-virginica\n",
      "149           5.9          3.0             5.1     1.800000  Iris-virginica\n",
      "150           6.5          2.0  Iris-virginica     1.230263             NaN\n",
      "151           6.5          3.2             5.1     2.000000             NaN\n",
      "152           6.5          3.2             5.1     5.200000             NaN\n",
      "\n",
      "[153 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# IMPUTATION: Fill missing values with the mean of each feature \n",
    "\n",
    "# Ensure to adjust this line according to whether your CSV file has headers or not\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "iris_data = pd.read_csv('iris_preprocess.csv', names=column_names)  # Remove 'header=None' if headers are in the first row of your CSV\n",
    "\n",
    "# Compute means for numeric columns only\n",
    "mean_values = iris_data.select_dtypes(include=[float, int]).mean()\n",
    "\n",
    "# Apply imputation\n",
    "data_imputed = iris_data.fillna(mean_values)\n",
    "print(data_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0336051-1d82-4f9f-952c-0011deece388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width    petal_length  petal_width           class\n",
      "0             5.1          3.5             1.4          0.2     Iris-setosa\n",
      "1             4.9          3.0             1.4          0.2     Iris-setosa\n",
      "2             4.7          3.2             1.3          0.2     Iris-setosa\n",
      "3             4.6          3.1             1.5          0.2     Iris-setosa\n",
      "4             5.0          3.6             1.4          0.2     Iris-setosa\n",
      "..            ...          ...             ...          ...             ...\n",
      "148           6.2          3.4             5.4          2.3  Iris-virginica\n",
      "149           5.9          3.0             5.1          1.8  Iris-virginica\n",
      "150           6.5          2.0  Iris-virginica          0.2     Iris-setosa\n",
      "151           6.5          3.2             5.1          2.0     Iris-setosa\n",
      "152           6.5          3.2             5.1          5.2     Iris-setosa\n",
      "\n",
      "[153 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with the mode of each feature\n",
    "data_imputed = iris_data.fillna(iris_data.mode().iloc[0])\n",
    "print(data_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70a84ec-c44d-41f6-9597-b31568ffc630",
   "metadata": {},
   "source": [
    "### Data Normalization\n",
    "\n",
    "Data normalization is a technique used to scale the features of a dataset to a specific range, typically between 0 and 1. Normalization helps to ensure that all features contribute equally to the learning process and can improve the convergence of certain machine learning algorithms. The most common normalization technique is Min-Max scaling, which scales the features to a fixed range.Python code to perform Min-Max scaling using scikit-learn:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "958d047a-9ace-4d1a-8075-6f660d5c9513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "# Select only the numeric columns for scaling\n",
    "numeric_columns = iris_data.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the numeric data\n",
    "normalized_array = scaler.fit_transform(numeric_columns)\n",
    "\n",
    "# Create a DataFrame from the normalized array and add the class column back\n",
    "data_normalized = pd.DataFrame(normalized_array, columns=numeric_columns.columns)\n",
    "data_normalized['class'] = iris_data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "415dc9a1-c4ba-4df8-8f33-8f21a7b8d64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_width           class\n",
      "0        0.222222     0.625000     0.019608     Iris-setosa\n",
      "1        0.166667     0.416667     0.019608     Iris-setosa\n",
      "2        0.111111     0.500000     0.019608     Iris-setosa\n",
      "3        0.083333     0.458333     0.019608     Iris-setosa\n",
      "4        0.194444     0.666667     0.019608     Iris-setosa\n",
      "..            ...          ...          ...             ...\n",
      "148      0.527778     0.583333     0.431373  Iris-virginica\n",
      "149      0.444444     0.416667     0.333333  Iris-virginica\n",
      "150      0.611111     0.000000          NaN             NaN\n",
      "151      0.611111     0.500000     0.372549             NaN\n",
      "152      0.611111     0.500000     1.000000             NaN\n",
      "\n",
      "[153 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9606131-eddb-4ee0-9400-66a4af198ecc",
   "metadata": {},
   "source": [
    "### Data Standardization\n",
    "\n",
    "Data standardization is another technique used to transform the features of a dataset to have zero mean and unit variance. Standardization is useful when the features have different scales or when the algorithm assumes that the data follows a Gaussian distribution. Python code to perform standardization using scikit-learn:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a56a683-cee4-4cbd-aadd-082d4f81168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# Select only the numeric columns for scaling\n",
    "numeric_columns = iris_data.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Create a StandardScaler object \n",
    "scaler = StandardScaler() \n",
    "\n",
    "\n",
    "# Fit and transform the data \n",
    "data_standardized = scaler.fit_transform(numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2eef59f4-694e-4a89-b53c-48da415e9e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.91970918  1.03298043 -1.2498566 ]\n",
      " [-1.1629512  -0.11228048 -1.2498566 ]\n",
      " [-1.40619321  0.34582388 -1.2498566 ]\n",
      " [-1.52781422  0.1167717  -1.2498566 ]\n",
      " [-1.04133019  1.26203261 -1.2498566 ]\n",
      " [-0.55484616  1.94918916 -1.00722799]\n",
      " [-1.52781422  0.80392825 -1.1285423 ]\n",
      " [-1.04133019  0.80392825 -1.2498566 ]\n",
      " [-1.77105623 -0.34133266 -1.2498566 ]\n",
      " [-1.1629512   0.1167717  -1.37117091]\n",
      " [-0.55484616  1.4910848  -1.2498566 ]\n",
      " [-1.2845722   0.80392825 -1.2498566 ]\n",
      " [-1.2845722  -0.11228048 -1.37117091]\n",
      " [-1.89267724 -0.11228048 -1.37117091]\n",
      " [-0.06836213  2.17824134 -1.2498566 ]\n",
      " [-0.18998314  3.09445008 -1.00722799]\n",
      " [-0.55484616  1.94918916 -1.00722799]\n",
      " [-0.91970918  1.03298043 -1.1285423 ]\n",
      " [-0.18998314  1.72013698 -1.1285423 ]\n",
      " [-0.91970918  1.72013698 -1.1285423 ]\n",
      " [-0.55484616  0.80392825 -1.2498566 ]\n",
      " [-0.91970918  1.4910848  -1.00722799]\n",
      " [-1.52781422  1.26203261 -1.2498566 ]\n",
      " [-0.91970918  0.57487607 -0.88591368]\n",
      " [-1.2845722   0.80392825 -1.2498566 ]\n",
      " [-1.04133019 -0.11228048 -1.2498566 ]\n",
      " [-1.04133019  0.80392825 -1.00722799]\n",
      " [-0.79808818  1.03298043 -1.2498566 ]\n",
      " [-0.79808818  0.80392825 -1.2498566 ]\n",
      " [-1.40619321  0.34582388 -1.2498566 ]\n",
      " [-1.2845722   0.1167717  -1.2498566 ]\n",
      " [-0.55484616  0.80392825 -1.00722799]\n",
      " [-0.79808818  2.40729353 -1.37117091]\n",
      " [-0.43322516  2.63634571 -1.2498566 ]\n",
      " [-1.1629512   0.1167717  -1.37117091]\n",
      " [-1.04133019  0.34582388 -1.2498566 ]\n",
      " [-0.43322516  1.03298043 -1.2498566 ]\n",
      " [-1.1629512   0.1167717  -1.37117091]\n",
      " [-1.77105623 -0.11228048 -1.2498566 ]\n",
      " [-0.91970918  0.80392825 -1.2498566 ]\n",
      " [-1.04133019  1.03298043 -1.1285423 ]\n",
      " [-1.64943522 -1.71564576 -1.1285423 ]\n",
      " [-1.77105623  0.34582388 -1.2498566 ]\n",
      " [-1.04133019  1.03298043 -0.76459938]\n",
      " [-0.91970918  1.72013698 -1.00722799]\n",
      " [-1.2845722  -0.11228048 -1.1285423 ]\n",
      " [-0.91970918  1.72013698 -1.2498566 ]\n",
      " [-1.52781422  0.34582388 -1.2498566 ]\n",
      " [-0.67646717  1.4910848  -1.2498566 ]\n",
      " [-1.04133019  0.57487607 -1.2498566 ]\n",
      " [ 1.39108995  0.34582388  0.20591507]\n",
      " [ 0.66136391  0.34582388  0.32722938]\n",
      " [ 1.26946894  0.1167717   0.32722938]\n",
      " [-0.43322516 -1.71564576  0.08460077]\n",
      " [ 0.78298491 -0.57038485  0.32722938]\n",
      " [-0.18998314 -0.57038485  0.08460077]\n",
      " [ 0.5397429   0.57487607  0.44854369]\n",
      " [-1.1629512  -1.48659358 -0.27934215]\n",
      " [ 0.90460592 -0.34133266  0.08460077]\n",
      " [-0.79808818 -0.79943703  0.20591507]\n",
      " [-1.04133019 -2.40280231 -0.27934215]\n",
      " [ 0.05325887 -0.11228048  0.32722938]\n",
      " [ 0.17487988 -1.94469794 -0.27934215]\n",
      " [ 0.29650089 -0.34133266  0.20591507]\n",
      " [-0.31160415 -0.34133266  0.08460077]\n",
      " [ 1.02622693  0.1167717   0.20591507]\n",
      " [-0.31160415 -0.11228048  0.32722938]\n",
      " [-0.06836213 -0.79943703 -0.27934215]\n",
      " [ 0.41812189 -1.94469794  0.32722938]\n",
      " [-0.31160415 -1.25754139 -0.15802785]\n",
      " [ 0.05325887  0.34582388  0.6911723 ]\n",
      " [ 0.29650089 -0.57038485  0.08460077]\n",
      " [ 0.5397429  -1.25754139  0.32722938]\n",
      " [ 0.29650089 -0.57038485 -0.03671354]\n",
      " [ 0.66136391 -0.34133266  0.08460077]\n",
      " [ 0.90460592 -0.11228048  0.20591507]\n",
      " [ 1.14784793 -0.57038485  0.20591507]\n",
      " [ 1.02622693 -0.11228048  0.56985799]\n",
      " [ 0.17487988 -0.34133266  0.32722938]\n",
      " [-0.18998314 -1.02848921 -0.27934215]\n",
      " [-0.43322516 -1.48659358 -0.15802785]\n",
      " [-0.43322516 -1.48659358 -0.27934215]\n",
      " [-0.06836213 -0.79943703 -0.03671354]\n",
      " [ 0.17487988 -0.79943703  0.44854369]\n",
      " [-0.55484616 -0.11228048  0.32722938]\n",
      " [ 0.17487988  0.80392825  0.44854369]\n",
      " [ 1.02622693  0.1167717   0.32722938]\n",
      " [ 0.5397429  -1.71564576  0.08460077]\n",
      " [-0.31160415 -0.11228048  0.08460077]\n",
      " [-0.43322516 -1.25754139  0.08460077]\n",
      " [-0.43322516 -1.02848921 -0.03671354]\n",
      " [ 0.29650089 -0.11228048  0.20591507]\n",
      " [-0.06836213 -1.02848921 -0.03671354]\n",
      " [-1.04133019 -1.71564576 -0.27934215]\n",
      " [-0.31160415 -0.79943703  0.08460077]\n",
      " [-0.18998314 -0.11228048 -0.03671354]\n",
      " [-0.18998314 -0.34133266  0.08460077]\n",
      " [ 0.41812189 -0.34133266  0.08460077]\n",
      " [-0.91970918 -1.25754139 -0.15802785]\n",
      " [-0.18998314 -0.57038485  0.08460077]\n",
      " [ 0.5397429   0.57487607  1.54037244]\n",
      " [-0.06836213 -0.79943703  0.8124866 ]\n",
      " [ 1.51271095 -0.11228048  1.05511522]\n",
      " [ 0.5397429  -0.34133266  0.6911723 ]\n",
      " [ 0.78298491 -0.11228048  1.17642952]\n",
      " [ 2.12081599 -0.11228048  1.05511522]\n",
      " [-1.1629512  -1.25754139  0.56985799]\n",
      " [ 1.75595297 -0.34133266  0.6911723 ]\n",
      " [ 1.02622693 -1.25754139  0.6911723 ]\n",
      " [ 1.63433196  1.26203261  1.54037244]\n",
      " [ 0.78298491  0.34582388  0.93380091]\n",
      " [ 0.66136391 -0.79943703  0.8124866 ]\n",
      " [ 1.14784793 -0.11228048  1.05511522]\n",
      " [-0.18998314 -1.25754139  0.93380091]\n",
      " [-0.06836213 -0.57038485  1.41905814]\n",
      " [ 0.66136391  0.34582388  1.29774383]\n",
      " [ 0.78298491 -0.11228048  0.6911723 ]\n",
      " [ 2.24243699  1.72013698  1.17642952]\n",
      " [ 2.24243699 -1.02848921  1.29774383]\n",
      " [ 0.17487988 -1.94469794  0.32722938]\n",
      " [ 1.26946894  0.34582388  1.29774383]\n",
      " [-0.31160415 -0.57038485  0.93380091]\n",
      " [ 2.24243699 -0.57038485  0.93380091]\n",
      " [ 0.5397429  -0.79943703  0.6911723 ]\n",
      " [ 1.02622693  0.57487607  1.05511522]\n",
      " [ 1.63433196  0.34582388  0.6911723 ]\n",
      " [ 0.41812189 -0.57038485  0.6911723 ]\n",
      " [ 0.29650089 -0.11228048  0.6911723 ]\n",
      " [ 0.66136391 -0.57038485  1.05511522]\n",
      " [ 1.63433196 -0.11228048  0.44854369]\n",
      " [ 1.87757397 -0.57038485  0.8124866 ]\n",
      " [ 2.48567901  1.72013698  0.93380091]\n",
      " [ 0.66136391 -0.57038485  1.17642952]\n",
      " [ 0.5397429  -0.57038485  0.32722938]\n",
      " [ 0.29650089 -1.02848921  0.20591507]\n",
      " [ 2.24243699 -0.11228048  1.29774383]\n",
      " [ 0.5397429   0.80392825  1.41905814]\n",
      " [ 0.66136391  0.1167717   0.6911723 ]\n",
      " [ 0.17487988 -0.11228048  0.6911723 ]\n",
      " [ 1.26946894  0.1167717   1.05511522]\n",
      " [ 1.02622693  0.1167717   1.41905814]\n",
      " [ 1.26946894  0.1167717   1.29774383]\n",
      " [-0.06836213 -0.79943703  0.8124866 ]\n",
      " [ 1.14784793  0.34582388  1.29774383]\n",
      " [ 1.02622693  0.57487607  1.54037244]\n",
      " [ 1.02622693 -0.11228048  1.29774383]\n",
      " [ 0.5397429  -1.25754139  0.8124866 ]\n",
      " [ 0.78298491 -0.11228048  0.93380091]\n",
      " [ 0.41812189  0.80392825  1.29774383]\n",
      " [ 0.05325887 -0.11228048  0.6911723 ]\n",
      " [ 0.78298491 -2.40280231         nan]\n",
      " [ 0.78298491  0.34582388  0.93380091]\n",
      " [ 0.78298491  0.34582388  4.81585872]]\n"
     ]
    }
   ],
   "source": [
    "print(data_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049162d4-62ce-4b93-8d67-1b0563437148",
   "metadata": {},
   "source": [
    "### Applying Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a30902b-d48c-434d-8e99-cb61af7c64af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "# Read the CSV file. Adjust the header parameter as needed based on the file structure.\n",
    "# If the file contains headers, you should use header=0 or omit it, otherwise use header=None and provide column names.\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "iris_data = pd.read_csv('iris_preprocess.csv', header=None, names=column_names)\n",
    "\n",
    "# Separate features and target\n",
    "X = iris_data.drop('species', axis=1)\n",
    "y = iris_data['species']\n",
    "\n",
    "# Ensure all features are numeric (not strictly necessary here, but good practice for other data)\n",
    "X = X.apply(pd.to_numeric, errors='coerce')  # Coerce errors will turn any non-numeric values to NaN, which you might handle by imputing\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the features\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Optionally, convert the normalized features back to a DataFrame for better usability\n",
    "X_normalized_df = pd.DataFrame(X_normalized, columns=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "57d5a097-cdf4-4d3b-a12d-0926e94bc31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types in the DataFrame:\n",
      "sepal_length    float64\n",
      "sepal_width     float64\n",
      "petal_length     object\n",
      "petal_width     float64\n",
      "species          object\n",
      "dtype: object\n",
      "First few rows of features (X):\n",
      "   sepal_length  sepal_width petal_length  petal_width\n",
      "0           5.1          3.5          1.4          0.2\n",
      "1           4.9          3.0          1.4          0.2\n",
      "2           4.7          3.2          1.3          0.2\n",
      "3           4.6          3.1          1.5          0.2\n",
      "4           5.0          3.6          1.4          0.2\n",
      "Error during scaling: could not convert string to float: 'Iris-virginica'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset, make sure to correctly handle the header if it exists.\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "iris_data = pd.read_csv('iris_preprocess.csv', header=None, names=column_names)\n",
    "\n",
    "# Print the data types to confirm the structure\n",
    "print(\"Data types in the DataFrame:\")\n",
    "print(iris_data.dtypes)\n",
    "\n",
    "# Separate features and target\n",
    "X = iris_data.drop('species', axis=1)  # Dropping the 'species' column to keep only numeric features\n",
    "y = iris_data['species']  # This is the categorical target variable\n",
    "\n",
    "# Verify the content of X\n",
    "print(\"First few rows of features (X):\")\n",
    "print(X.head())\n",
    "\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Standardize the features (ensure X contains only numeric columns)\n",
    "try:\n",
    "    X_standardized = scaler.fit_transform(X)\n",
    "    # Optionally, convert the standardized features back to a DataFrame for better usability\n",
    "    X_standardized_df = pd.DataFrame(X_standardized, columns=X.columns)\n",
    "    print(\"Standardized features:\")\n",
    "    print(X_standardized_df.head())\n",
    "except Exception as e:\n",
    "    print(\"Error during scaling:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d7219f-f840-4fbe-92be-48328d696a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
